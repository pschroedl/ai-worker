--- app/pipelines/text_to_speech.py	2024-08-02 20:39:18.658448901 +0000
+++ app/pipelines/text_to_speech_updated.py	2024-08-02 20:39:02.304028206 +0000
@@ -12,21 +12,21 @@
 class TextToSpeechPipeline(Pipeline):
     def __init__(self, model_id: str):
         self.model_id = model_id
-        # kwargs = {"cache_dir": get_model_dir()}
+        if os.getenv("MOCK_PIPELINE", "").strip().lower() == "true":
+            logger.info("Mocking TextToSpeechPipeline for %s", model_id)
+            return
 
-        # folder_name = file_download.repo_folder_name(
-        #     repo_id=model_id, repo_type="model"
-        # )
-        # folder_path = os.path.join(get_model_dir(), folder_name)
         self.device = get_torch_device()
-        # preload FastSpeech 2 & hifigan
         self.TTS_tokenizer = FastSpeech2ConformerTokenizer.from_pretrained("espnet/fastspeech2_conformer", cache_dir=get_model_dir())
         self.TTS_model = FastSpeech2ConformerModel.from_pretrained("espnet/fastspeech2_conformer", cache_dir=get_model_dir()).to(self.device)
         self.TTS_hifigan = FastSpeech2ConformerHifiGan.from_pretrained("espnet/fastspeech2_conformer_hifigan", cache_dir=get_model_dir()).to(self.device)
 
-
     def __call__(self, text):
-        # generate unique filename
+        if os.getenv("MOCK_PIPELINE", "").strip().lower() == "true":
+            unique_audio_filename = f"{uuid.uuid4()}.wav"
+            audio_path = os.path.join("/tmp/", unique_audio_filename)
+            sf.write(audio_path, [0] * 22050, samplerate=22050)
+            return audio_path
         unique_audio_filename = f"{uuid.uuid4()}.wav"
         audio_path = os.path.join("/tmp/", unique_audio_filename)
 
@@ -35,19 +35,11 @@
         return audio_path
 
     def generate_audio(self, text, output_file_name):
-        # Tokenize input text
         inputs = self.TTS_tokenizer(text, return_tensors="pt").to(self.device)
-        
-        # Ensure input IDs remain in Long tensor type
         input_ids = inputs["input_ids"].to(self.device)
-        
-        # Generate spectrogram
         output_dict = self.TTS_model(input_ids, return_dict=True)
         spectrogram = output_dict["spectrogram"]
-
-        # Convert spectrogram to waveform
         waveform = self.TTS_hifigan(spectrogram)
-
         sf.write(output_file_name, waveform.squeeze().detach().cpu().numpy(), samplerate=22050)
         return output_file_name
     
